import os
import asyncio
from typing import Dict, List, Optional
from anthropic import Anthropic
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIResponseGenerator:
    def __init__(self, demo_mode: bool = True):
        self.demo_mode = demo_mode
        self.client = None
        
        if not demo_mode:
            try:
                api_key = os.getenv('ANTHROPIC_API_KEY')
                if api_key:
                    self.client = Anthropic(api_key=api_key)
                    logger.info("ðŸš€ CLAUDE AI CLIENT INITIALIZED - Ready for production AI responses")
                    logger.info(f"   ðŸŽ¯ Model: claude-sonnet-4-20250514")
                    logger.info(f"   ðŸ”‘ API Key: {api_key[:10]}...{api_key[-4:]}")
                    logger.info("   âœ¨ All responses will be generated by Claude Sonnet 4")
                else:
                    logger.warning("âŒ No Claude API key found in environment variables")
                    logger.warning("ðŸ”„ Falling back to demo mode with pre-written templates")
                    self.demo_mode = True
            except Exception as e:
                logger.error(f"âŒ Failed to initialize Claude client: {e}")
                logger.warning("ðŸ”„ Falling back to demo mode due to initialization error")
                self.demo_mode = True
        else:
            logger.info("ðŸŽ­ DEMO MODE ACTIVE - AI responses will be simulated")
            logger.info("   ðŸ“ Using pre-written response templates")
            logger.info("   ðŸ’¡ Set DEMO_MODE=false for real Claude AI responses")
    
    def generate_response(self, ticket_data: Dict) -> Dict:
        if self.demo_mode:
            logger.info("ðŸŽ­ Demo mode: Generating simulated AI response (no Claude API call)")
            return self._generate_demo_response(ticket_data)
        
        try:
            sentiment = ticket_data.get('sentiment', 'neutral')
            priority = ticket_data.get('priority', 'low')
            message = ticket_data.get('original_message', '')
            escalation = ticket_data.get('needs_escalation', False)
            ticket_id = ticket_data.get('ticket_id', 'unknown')
            
            logger.info(f"ðŸ¤– CLAUDE API REQUEST - Generating AI response for ticket {ticket_id}")
            logger.info(f"   ðŸ“Š Input: sentiment={sentiment}, priority={priority}, escalation={escalation}")
            logger.info(f"   ðŸ’¬ Message preview: {message[:50]}{'...' if len(message) > 50 else ''}")
            
            # Create prompt based on ticket analysis
            prompt = self._create_prompt(message, sentiment, priority, escalation)
            
            logger.info("ðŸŒ Calling Claude Sonnet 4 API...")
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=300,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            ai_response = response.content[0].text
            response_type = self._determine_response_type(priority, escalation)
            
            logger.info(f"âœ… CLAUDE API SUCCESS - Generated {response_type} response")
            logger.info(f"   ðŸ“ Response preview: {ai_response[:80]}{'...' if len(ai_response) > 80 else ''}")
            logger.info(f"   ðŸŽ¯ Model used: claude-sonnet-4-20250514")
            logger.info(f"   ðŸ”¢ Token usage: {len(ai_response.split())} words in response")
            
            return {
                "ai_response": ai_response,
                "response_type": response_type,
                "confidence": 0.85,
                "escalation_recommended": escalation,
                "source": "claude-sonnet-4-api"
            }
            
        except Exception as e:
            logger.error(f"âŒ CLAUDE API ERROR - Failed to generate AI response: {e}")
            logger.warning("ðŸ”„ Falling back to demo response due to API error")
            return self._generate_demo_response(ticket_data)
    
    def _create_prompt(self, message: str, sentiment: str, priority: str, escalation: bool) -> str:
        base_prompt = f"""
You are a customer service AI assistant. Generate a professional, empathetic response to this customer message.

Customer Message: "{message}"
Sentiment Analysis: {sentiment}
Priority: {priority}
Needs Escalation: {escalation}

Guidelines:
- Be empathetic and understanding
- Address the customer's concerns directly
- If high priority or escalation needed, acknowledge urgency
- Provide clear next steps
- Keep response concise but thorough
- Match the appropriate tone for the situation

Generate a response:"""
        
        return base_prompt
    
    def _determine_response_type(self, priority: str, escalation: bool) -> str:
        if escalation or priority == "high":
            return "escalation"
        elif priority == "medium":
            return "priority"
        else:
            return "standard"
    
    def _generate_demo_response(self, ticket_data: Dict) -> Dict:
        sentiment = ticket_data.get('sentiment', 'neutral')
        priority = ticket_data.get('priority', 'low')
        escalation = ticket_data.get('needs_escalation', False)
        ticket_id = ticket_data.get('ticket_id', 'unknown')
        
        logger.info(f"ðŸŽ® DEMO RESPONSE - Generating simulated response for ticket {ticket_id}")
        logger.info(f"   ðŸ“Š Input: sentiment={sentiment}, priority={priority}, escalation={escalation}")
        logger.info("   ðŸ”§ Using pre-written templates (no AI model called)")
        
        # Demo responses based on sentiment and priority
        if escalation or priority == "high":
            responses = [
                "I sincerely apologize for the frustration you're experiencing. This issue has been escalated to our senior support team and you will receive a response within 2 hours. We take your concerns very seriously and are committed to resolving this immediately.",
                "I understand how urgent this is for you. I've immediately escalated your case to our priority support team. A senior specialist will contact you within the next hour to resolve this issue. Thank you for your patience.",
                "I'm truly sorry for the inconvenience this has caused. This matter requires immediate attention and has been forwarded to our escalation team. You can expect a call from a supervisor within 30 minutes."
            ]
        elif sentiment == "positive":
            responses = [
                "Thank you so much for your positive feedback! It's wonderful to hear that our service met your expectations. If you need any further assistance, please don't hesitate to reach out.",
                "We're delighted to hear about your positive experience! Your feedback motivates our team to continue providing excellent service. Is there anything else we can help you with today?"
            ]
        elif sentiment == "negative":
            responses = [
                "I'm sorry to hear about your disappointing experience. Let me work with you to resolve this issue right away. Could you please provide some additional details so I can better assist you?",
                "I apologize for the trouble you've encountered. Your satisfaction is important to us, and I'm here to help make this right. Let's work together to find a solution."
            ]
        else:
            responses = [
                "Thank you for reaching out to us. I'm here to help you with your inquiry. Could you please provide a bit more information so I can assist you better?",
                "I've received your message and I'm ready to help. Let me look into this for you and provide you with the best possible solution."
            ]
        
        import random
        selected_response = random.choice(responses)
        response_type = self._determine_response_type(priority, escalation)
        
        logger.info(f"âœ… DEMO RESPONSE COMPLETE - Generated {response_type} template response")
        logger.info(f"   ðŸ“ Response preview: {selected_response[:80]}{'...' if len(selected_response) > 80 else ''}")
        logger.info("   âš ï¸  This is a SIMULATED response (not from Claude AI)")
        
        return {
            "ai_response": selected_response,
            "response_type": response_type,
            "confidence": 0.92,
            "escalation_recommended": escalation,
            "source": "demo-templates"
        }

class ResponseTemplateManager:
    def __init__(self):
        self.templates = {
            "escalation": {
                "subject": "URGENT: Your Support Request - Immediate Attention Required",
                "template": "Dear {customer_name},\n\nI sincerely apologize for the urgent nature of your concern. Your case has been escalated to our senior support team.\n\n{ai_response}\n\nReference ID: {ticket_id}\nPriority: HIGH\n\nBest regards,\nCustomer Support Team"
            },
            "priority": {
                "subject": "Re: Your Support Request - Priority Response",  
                "template": "Dear {customer_name},\n\nThank you for contacting us. I understand the importance of your request.\n\n{ai_response}\n\nReference ID: {ticket_id}\n\nBest regards,\nCustomer Support Team"
            },
            "standard": {
                "subject": "Re: Your Support Request",
                "template": "Dear {customer_name},\n\nThank you for reaching out to us.\n\n{ai_response}\n\nReference ID: {ticket_id}\n\nBest regards,\nCustomer Support Team"
            }
        }
    
    def format_response(self, response_data: Dict, ticket_data: Dict) -> Dict:
        response_type = response_data.get('response_type', 'standard')
        template = self.templates.get(response_type, self.templates['standard'])
        
        formatted_response = template['template'].format(
            customer_name=ticket_data.get('customer_id', 'Valued Customer'),
            ai_response=response_data.get('ai_response', ''),
            ticket_id=ticket_data.get('ticket_id', 'Unknown')
        )
        
        return {
            "subject": template['subject'],
            "body": formatted_response,
            "response_type": response_type,
            "escalation_recommended": response_data.get('escalation_recommended', False)
        }